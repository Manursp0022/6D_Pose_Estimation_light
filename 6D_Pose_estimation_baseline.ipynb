{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44db447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from google.colab import drive\n",
    "\n",
    "# 1. Mount Google Drive\n",
    "print(\"Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Define source path in MyDrive\n",
    "# IMPORTANT: Please update this path to where your 'linemod_preprocessed.zip' file is located in your Google Drive.\n",
    "source_file_path = '/content/drive/MyDrive/Linemod_preprocessed.zip' # Example path, adjust as needed\n",
    "\n",
    "# 3. Define destination path\n",
    "destination_dir = '/content/6D_Pose_Estimation_light/dataset/'\n",
    "\n",
    "# Ensure destination directory exists\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# 4. Unzip the file directly to the destination directory\n",
    "if os.path.exists(source_file_path):\n",
    "    print(f\"Unzipping '{source_file_path}' directly to '{destination_dir}'...\")\n",
    "    # Use !unzip with -q for quiet output and -d to specify destination directory\n",
    "    !unzip -q \"{source_file_path}\" -d \"{destination_dir}\"\n",
    "    print(\"File unzipped successfully.\")\n",
    "else:\n",
    "    print(f\"Error: Source file not found at '{source_file_path}'.\")\n",
    "    print(\"Please ensure the 'linemod_preprocessed.zip' file exists in your Google Drive at the specified path, or update 'source_file_path'.\")\n",
    "\n",
    "print(f\"\\nContents of the destination folder in '{destination_dir}':\")\n",
    "!ls -F {destination_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "real_classes = {\n",
    "    0: '01',\n",
    "    1: '02',\n",
    "    2: '04',\n",
    "    3: '05',\n",
    "    4: '06',\n",
    "    5: '08',\n",
    "    6: '09',\n",
    "    7: '10',\n",
    "    8: '11',\n",
    "    9: '12',\n",
    "    10: '13',\n",
    "    11: '14',\n",
    "    12: '15'\n",
    "}\n",
    "\n",
    "models_info = \"/content/6D_Pose_Estimation_light/dataset/Linemod_preprocessed/models/models_info.yml\"\n",
    "\n",
    "# Lettura del file YAML\n",
    "with open(models_info, 'r') as f:\n",
    "    models_data = yaml.safe_load(f)\n",
    "\n",
    "# Popolazione del dizionario diam_pose\n",
    "diam_pose = {}\n",
    "for key, class_id in real_classes.items():\n",
    "    if int(class_id) in models_data:\n",
    "        diam_pose[key] = models_data[int(class_id)]['diameter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell: load YOLO (finetuned), RotationNet (checkpoint), pinhole and PoseEvaluator for LINEMOD ADD eval\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO                    # pip install ultralytics\n",
    "from models.RotationNet import RotationNet           # replace with your RotationNet implementation import\n",
    "from utils.pinholeFunction import get_3d_coordinates                    # replace with your pinhole function import\n",
    "from utils.PoseEvaluator import PoseEvaluator            # replace with your PoseEvaluator import\n",
    "from utils.posenet_dataset_ALL import LineModPoseDataset as LinemodDataset  # replace with your dataset import\n",
    "from utils.utils_geometric import crop_square_resize, quaternion_to_matrix   # replace with your crop function import\n",
    "import numpy as np\n",
    "\n",
    "# --- Paths (replace with actual files) ---\n",
    "YOLO_WEIGHTS = \"checkpoints\\\\yolo\\\\best.pt\"\n",
    "ROTNET_CHECKPOINT = \"checkpoints\\\\rotationNet\\\\best_posenet.pth\"\n",
    "LINEMOD_ROOT = \"/path/to/linemod\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# --- Load models ---\n",
    "yolo = YOLO(YOLO_WEIGHTS).to(DEVICE)\n",
    "\n",
    "rnet = RotationNet().to(DEVICE)  # adjust constructor args as needed\n",
    "ckpt = torch.load(ROTNET_CHECKPOINT, map_location=\"cpu\")\n",
    "state = ckpt.get(\"state_dict\", ckpt)\n",
    "rnet.load_state_dict(state)\n",
    "rnet.eval()\n",
    "\n",
    "# --- Dataset and evaluator ---\n",
    "dataset = LinemodDataset(LINEMOD_ROOT, split=\"eval\")  # adjust API as needed\n",
    "evaluator = PoseEvaluator()  # adjust API as needed\n",
    "\n",
    "val_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "# --- Helper: convert RotationNet output to (R,t) pose (implement for your model) ---\n",
    "\n",
    "\n",
    "# --- Run evaluation loop (example; adapt to your dataset/model APIs) ---\n",
    "for sample in val_loader:\n",
    "    img = sample[\"path\"].to(DEVICE)  # input image     \n",
    "    gt_t = sample.get(\"t\").to(DEVICE)  # ground-truth poses per object\n",
    "    gt_R = np.array(sample.get(\"R\")).reshape(3, 3).to(DEVICE)\n",
    "    obj_id = sample.get(\"obj_id\").to(DEVICE)\n",
    "\n",
    "    # Run YOLO on the image and normalize results into a plain list `detections`\n",
    "    results = yolo(img).to(DEVICE)            # ultralytics Results\n",
    "    detections = []\n",
    "    if len(results) > 0:\n",
    "        boxes = results[0].boxes\n",
    "        # boxes.xyxy is (N,4); boxes.conf and boxes.cls provide confidence and class\n",
    "        xywh = boxes.xywh\n",
    "        try:\n",
    "            confs = boxes.conf\n",
    "        except Exception:\n",
    "            confs = np.zeros(len(xywh))\n",
    "        try:\n",
    "            clss = boxes.cls\n",
    "        except Exception:\n",
    "            clss = np.zeros(len(xywh))\n",
    "        for i in range(len(xywh)):\n",
    "            x1, y1, w, h = xywh[i]\n",
    "            conf = float(confs[i]) if len(confs) > i else 0.0\n",
    "            cls = int(clss[i]) if len(clss) > i else 0\n",
    "            detections.append(np.array([x1, y1, w, h, conf, cls]))\n",
    "\n",
    "    preds = []\n",
    "    for det in detections:\n",
    "        \n",
    "        x1, y1, x2, y2, conf, cls = det.tolist()\n",
    "        if real_classes[int(cls)] == obj_id:\n",
    "        # convert to x,y,w,h for crop function\n",
    "            bbox_xywh = [x1, y1, w, h]\n",
    "            crop = crop_square_resize(img, bbox_xywh)\n",
    "            # preprocess crop as required by RotationNet\n",
    "\n",
    "            with torch.no_grad():\n",
    "                rot_out = rnet(crop)\n",
    "            R = quaternion_to_matrix(rot_out)\n",
    "            t = get_3d_coordinates\n",
    "            preds.append({\"obj_id\": int(cls), \"R\": R, \"t\": t})\n",
    "\n",
    "    evaluator.add(gt_poses=gt_poses, pred_poses=preds, obj_ids=obj_ids)\n",
    "\n",
    "print(\"ADD metric:\", evaluator.compute())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
